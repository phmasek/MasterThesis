\iffalse \bibliography{include/backmatter/magnus,include/backmatter/philip} \fi

\chapter{Related Work} \label{section:relatedwork} 
In this section we introduce (i) the process of identifying related work and (ii) discuss current research on scope of this study. % for the purpose of 
%This section aims to explore literature on using lightweight containers for deployment. 
% aims to show how this research fits into a larger research context 




%---------------------------------------------------%
%---------------------------------------------------%
\section{Gathering Related Work}
The snowballing search approach for systematic literature studies is used to find relevant literature on the topic of this paper. The snowballing approach is complementary to a traditional database search. Specifically, the reference list and citations of a paper are studied in order to identify additional papers. The snowballing search approach is used to ensure good coverage of current literature.\\

The guidelines for conducting a snowballing search approach, presented by Wohlin \cite{Wohlin} are followed for the search procedure. The steps to conduct a snowballing procedure involve (i) selecting a start set of papers, (ii) apply forward snowballing and (iii) apply backward snowballing on each paper identified in the start set respectively. This process iterates until no new papers are found. To identify a start set of papers, keywords are extracted from the research questions, taking synonyms into account. Formulating a search-string from keywords that are broad and cover multiple areas of research may result in collecting large amounts of literature that span different subject domains. For that reason, broad keywords should be broken down into more specific and detailed keywords specific to the study. The search string is then applied to a database that preferably searches multiple publishers in order to avoid publisher bias. The papers resulting from the database search are then screened according to inclusion/exclusion criteria. An exclusion criteria could state that all online material shall be excluded. \\

Backward and forward snowballing is then conducted on the start set. Backward snowballing is the process of studying the reference list to identify new papers. Looking at the place of reference and reading the title and abstract of the paper is a good starting point for inclusion, however, final inclusion states that the entire paper must be read \cite{Wohlin}. Subsequently, forward snowballing is the process of identifying papers that cite the paper under inspection. The same process of reading the title, abstract and place of reference is applied in order to include new literature that is found during the procedure. 

%-- Why Snowballing ?
%snowballing to ensure good coverage of literature
%snowballing over just a typical database search
%since we're writing about new tech, new papers must certainly reference at least one paper among previously releant studies

%-- Outline the steps in snowballing
%let’s outline them here, so the steps are clear. (what are iterations)
%Then, you describe the steps and their outcomes. 
%A figure showing the process could be used if you judge it fits

%-------------------------------
\subsection{Snowballing Search Results}
This section introduces the results from performing the snowballing search procedure described in the previous section. First the start-set is formulated and introduced, where two sets of iterations involving forwards and backwards snowballing is performed. 

\subsubsection*{Start Set}
A database search on Scopus \cite{scopus} is performed to identify the start set of papes from multiple publishers: the precise search string is found in \ref{search-string}. The search was conducted May 10, 2016 and resulted in finding 215 papers. A screening process was then applied to the 215 papers, adding papers to the start set upon meeting the inclusion/exclusion criteria. Papers were included if found to be about input/output benchmarking, CPU benchmarking or software deployment, within the subject area of virtual containers (preferably Docker) and/or within the context of cyber physical systems. Papers were excluded if not being peer-reviewed. In total, 8 candidates for inclusion were identified. The 8 papers are identified in table~\ref{lr-startset}, denoted P1, P2 and so on.

\begin{table}[H]
\centering
\begin{tabular}{p{15cm}}
TITLE-ABS-KEY(Performance OR Comparison OR Latency OR Evaluation OR Container-Based OR Linux Containers OR Lightweight Virtualization OR Container Cloud OR Docker) AND ( LIMIT-TO(SUBJAREA,"COMP" ) )
\end{tabular}
\caption{Search String}
\label{search-string}
\end{table}

%-----------------------%
\begin{table}[ht]
\begin{tabular}{lp{13cm}}
{[}P1{]}  & C. N. Mao, M. H. Huang, S. Padhy, S. T. Wang, W. C. Chung, Y. C. Chung, and C. H. Hsu, “Minimizing latency of real-time container cloud for software radio access networks,” in 2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom), Nov 2015, pp. 611–616.                                  \\
{[}P2{]}  & A. Krylovskiy, “Internet of things gateways meet linux containers: Performance evaluation and discussion,” in Internet of Things (WF-IoT), 2015 IEEE 2nd World Forum on, Dec 2015, pp. 222–227.                                                                                                                                      \\
{[}P3{]}  & M. Raho, A. Spyridakis, M. Paolino, and D. Raho, “Kvm, xen and docker: A performance analysis for arm based nfv and cloud computing,” in Information,Electronic and Electrical Engineering (AIEEE), 2015 IEEE 3rd Workshop onAdvances in, Nov 2015, pp. 1–8.                                                                         \\
{[}P4{]}  & R. Morabito, J. Kj\"allman, and M. Komu, “Hypervisors vs. lightweight virtualization: A performance comparison,” in Proceedings of the 2015 IEEE Interational Conference on Cloud Engineering, ser. IC2E ’15. Washington, DC, USA: IEEE Computer Society, 2015, pp. 386–393.                                                      \\
{[}P5{]}  & M. G. Xavier, I. C. D. Oliveira, F. D. Rossi, R. D. D. Passos, K. J. Matteussi, and C. A. F. D. Rose, “A performance isolation analysis of disk-intensive workoads on container-based clouds,” in 2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing, March 2015, pp. 253–260. \\
{[}P6{]}  & W. Felter, A. Ferreira, R. Rajamony, and J. Rubio, “An updated performance comparison of virtual machines and linux containers,” in Performance Analysis of Systems and Software (ISPASS), 2015 IEEE International Symposium on, March 2015, pp. 171–172.                                                                            \\
{[}P7{]}  & C. Ruiz, E. Jeanvoine, and L. Nussbaum, “Performance evaluation of containers for hpc,” in Euro-Par 2015: Parallel Processing Workshops: Euro-Par 2015 International Workshops, Vienna, Austria, August 24-25, 2015, Revised Selected Papers. Cham: Springer International Publishing, 2015, pp. 813–824. \\
{[}P8{]}  & R. Wu, Y. Chen, E. Blasch, B. Liu, G. Chen, and D. Shen, “A container-based elastic cloud architecture for real-time full-motion video (fmv) target tracking,” in 2014 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), Oct 2014, pp. 1–8. 
\end{tabular}
\centering
\caption{Start Set}
\label{lr-startset}
\end{table}
%-----------------------%
%------Iteration 1------ 
\subsubsection*{Iteration 1: Backward Snowballing}
\textbf{P1} includes 26 references where one reference is already included in the start set (paper P6). Based on the inclusion criteria, one paper was included. The paper identified and thus included in the start set is: \\

%-------------------------------
\begin{labeling}{[{[}C10{]}]}
\item [{[}\textbf{C1}{]}]  M. G. Xavier, M. V. Neves, F. D. Rossi, T. C. Ferreto, T. Lange and C. A. F. De Rose, “Performance Evaluation of Container-Based Virtualization for High Performance Computing Environments,“ 2013 21st Euromicro International Conference on Parallel, Distributed, and Network-Based Processing, Belfast, 2013, pp. 233-240.
\item
\end{labeling}
%-------------------------------

Table~\ref{back-snow} shows the result of backward snowballing on the remaining eight papers. The results are presented in a table to avoid redundant text as the process and results of backward snowballing for each paper are very similar. In all papers, except P1, no new papers matched the inclusion criteria after reading the title and abstract. Furthermore, most of the papers in the start set reference to each other, as seen in column three of table~\ref{back-snow}. All papers in the start set contain reference to C1, except papers P2 and P8. Similarly, all papers in the start set reference to P6 except papers P5, P6 and P8. This shows that there is a strong connection between all papers in the start set. 

%-------------------------------
\begin{table}[H]
\begin{tabular}{|>{\centering\bfseries}m{1in} |>{\centering}m{1in}| >{\centering}m{1in} |>{\centering\arraybackslash}m{1in}|}
\hline
\textbf{Start Set Paper} & \textbf{No. References} & \textbf{Reference to Start Set} & \textbf{New Papers Identified} \\ \hline
\textbf{P1}              & 26                      & P6                                          & C1                  \\ \hline
\textbf{P2}              & 21                      & P6, P4                                      & 0                   \\ \hline
\textbf{P3}              & 47                      & P6, C1                                      & 0                   \\ \hline
\textbf{P4}              & 42                      & P6, P2, C1                                  & 0                   \\ \hline
\textbf{P5}              & 46                      & C1                                          & 0                   \\ \hline
\textbf{P6}              & 50                      & C1                                          & 0                   \\ \hline
\textbf{P7}              & 19                      & P6, C1                                      & 0                   \\ \hline
\textbf{P8}              & 18                      & 0                                           & 0                   \\ \hline
\end{tabular}
\centering
\caption{Results from Backward Snowballing in Iteration 1}
\label{back-snow}
\end{table}
%-------------------------------

\subsubsection*{Iteration 1: Forward Snowballing}
The next step is to examine the citations towards all papers that are in the start set. All papers were searched for citations using Google Scholar. The Scopus database was chosen not to be used for the forward snowballing procedure since it was shown that Google Scholar was more accurate in finding cited papers. The exclusion criteria for this snowballing search procedure excludes all non peer reviewed papers. However, during the forward snowballing search, a very relevant paper was found in regards to this study. It was then decided to include the paper as part of the related work. The specific paper included is: \\


\begin{labeling}{[{[}C10{]}]}
\item [{[}\textbf{C2}{]}]  Welch, James Matthew. Performance Optimization of Linux Networking for Latency-Sensitive Virtual Systems. Diss. ARIZONA STATE UNIVERSITY, 2015.

\item
\end{labeling}

\begin{table}[H]
\begin{tabular}{|>{\centering\bfseries}m{1in} |>{\centering}m{1in}|>{\centering\arraybackslash}m{1.8in}|}
\hline
\textbf{Start Set Paper} & \textbf{No. Citations}  & \textbf{New Papers Identified} \\ \hline
\textbf{P1}              & 0                       & 0                             \\ \hline
\textbf{P2}              & 0                       & 0                             \\ \hline
\textbf{P3}              & 0                       & 0                             \\ \hline
\textbf{P4}              & 8                       & C2				               \\ \hline
\textbf{P5}              & 2                       & 0                             \\ \hline
\textbf{P6}              & 81                      & 0                             \\ \hline
\textbf{P7}              & 4                       & 0                             \\ \hline
\textbf{P8}              & 1                       & 0                             \\ \hline
\end{tabular}
\centering
\caption{Results from Forward Snowballing in Iteration 1}
\label{forward-snow}
\end{table}

\subsubsection*{Iteration 2: Backward Snowballing}
Two additional papers to the start set were found in iteration one of the snowballing procedure. Thus, backward and forward snowballing is applied to C1 and C2.\\ 

\textbf{C1} has 32 references. From the 32 references, 16 references is excluded based on being references to online material. A large number of the resulting references have already been analysed in the previous iteration. No new papers were identified for inclusion.\\ 

\textbf{C2} has 69 references with reference to C1, P4, P6. No additional candidates for inclusion were found when studying the reference list of the paper.

\subsubsection*{Iteration 2: Forward Snowballing}
\textbf{C1} has been cited by 104 papers. When reviewing the list of cited papers, many of them have already been reviewed during the snowballing procedure.  Analysing the list of papers resulted in no additional candidates for inclusion.\\ 
 
\textbf{C2} has no citations. This is expected since C2 is not a published paper. 


\subsection{Outcome}
The snowballing search procedure resulted in finding nine papers during the database search. Two additional papers were identified during forward and backward snowballing. The snowballing procedure enabled good coverage of literature for related work and identified the current status of research in the topic of container virtualization. 
%a qualitative outcome of the snowballing procedure. What did it actually give us, and do for the paper? 
%However, since there was only one new paper included in the start-set during the backward snowballing, this sheds light on the fact that this study is within a narrow scope, and further motivates the need for carrying out this study. 

%What did we get out of doing the snowballing

%--------------------------------------------%
%--------------------------------------------%
\section{Related Work} 
% what is missing, what do we need to answer the research questions, what is there


C. Berger \cite{cberger} presents the exploration of a deployment strategy in the context of self-driving vehicles that utilises lightweight Docker containers. The deployment strategy makes use of a number of Docker containers that build and ship signed packages in a container ready for use. However, the paper does not look to identify the precise performance overhead when using Docker as part of the deployment strategy but addresses the need for it in future work. The deployment of software in \cite{cberger} exemplifies a possible deployment pipeline for resource constrained CPSs, that can be used as inspiration when investigating software deployment by using Docker.\\

The authors of \cite{2iot} identify the challenge of deploying, maintaining and configuring software for IoT gateways and investigate using virtual containers to solve these challenges. The authors identify the performance overhead of using Docker as a deployment platform on two different versions of the Raspberry Pi System on Chip (SoC) computer \cite{raspberry}. They identify that there are clear benefits containerizing applications for deployment on resource constrained devices and further identify the need for such research is the field for IoT applications. This shows there exists a need for continuous deployment for embedded, resource contained and high performing applications. The authors of \cite{2iot} recommend a case-by-case analysis when considering using Docker as a deployment platform for IoT devices. The case-by-case analysis is important as in \cite{gonz} the study also experiment with Docker on a Raspberry Pi SoC computer but do not report any substantial degradation in performance. Further use of Docker as a deployment platform is exemplified in \cite{gonz}. The authors of \cite{gonz} explore using Docker as a deployment platform for a generic modular architecture for industrial automated cyber physical systems. A use case of the modular architecture is applied to the development of an automated guided vehicular CPS. The authors state that having a modular architecture, in the form of Docker containers, decouples the complexity of CPSs into simpler subsystems, that different teams can individually develop on. Development teams can work individually on seperate subsystems and utilise Dockerhub, the team collaboration feature built into Docker. The authors of \cite{gonz} conclude that using a real-time enabled Linux kernel is needed for further development of the architecture. \\

In \cite{p6} the paper investigates the performance overhead of using virtual machines, Docker and compares the performance to native execution in the context of cloud computing. To analyse the processing overhead of using Docker, a lossless data compressions utility is used in various execution enviroments. The authors conclude containers have almost no overhead and reccomend a case-by-case analysis as using network address translation and the AUFS storage driver are the only two factors that introduce considerable overhead. However, the factors is likely to become improved in the future. \\

In a study presented by Mao et. al, the authors investigate the next generation of Radio Access Networks (RANs) used by Telecom providers. Traditional RANs are moving towards software as a service in the cloud \cite{p1} due to being hardware dependent equipment which are expensive and lack scalability. Moving traditional RANs to the cloud as software RANs is a challenging task due to the latency requirements of cellular networks: a similar challenge for software with high hardware dependability and time-sensitivity face the domain of autonomous vehicles. To overcome the time-sensitive requirements of software RANs, the authors use a real-time enabled Linux kernel, specifically the RT\_preempt patch, and measure computational and networking latency when using Docker for real-time applications. The cyclic test \cite{cycl} is used to measure computational latency and is a common tool to measure real-time capabilities of an operating system. However, the cyclic test is not comparable to a CPS as it lacks a supportive middleware. The worst case execution time in \cite{p1} is measured and reported in the study. The results of the study show that running real-time applications inside a Docker container achieves near-native performance, while the performance of virtual machines incur much higher latencies \cite{p1}. However, running multiple Docker containers on different hosts incur higher overhead \cite{p1}. Since CPSs may involve multiple computing nodes, measuring the performance of Docker on multiple hosts for real-time computations requires investigation if considering Docker as a deployment platform for multiple computing nodes.  \\

In a study presented by Welch \cite{c2}, the author identifies the performance overhead of using Docker for latency sensitive applications in the context of cloud computing. In \cite{c2}, the RT\_preempt kernel patch for Linux Kernel 3.18.20 is used to identify the networking performance of Docker containers in comparison to virtual machines. The results show that the Docker containers have generally higher bandwidth and lower latency than virtual machines. However, in both \cite{Andreas} and \cite{p6} the Network Address Translation (NAT) protocol introduces considerable overhead. NAT is needed when mapping a network to a single internet protocol (IP) address. Further research on this topic is required if the requirements for a CPS require independent IP address for multiple containers. \\

In papers \cite{p6,c2,p3,p4,p7,c1} they state that overhead by using Docker is negligible and CPU, memory, disk and network performance is near native. However, \cite{p5} presents results on the performance overhead of Docker and recommend not combining disk and memory intensive workloads into different containers due in an apparent degradation of performance they observers. They suggest consolidating I/O and CPU intensive workloads to alleviate this problem. \\

In \cite{p8}, the authors experiment with using multiple Docker containers for parallel processing to achieve real-time image processing. This is another benefit of using Docker as a deployment platform. If the resources of computing nodes allow for scaling up important processes in a CPS, one can run multiple Docker containers tasked with the same responsibility to produce an output faster (i.e parralell processing). The authors of \cite{p8} develop a drone tasked with tracking three mobile robots from a video stream. The video stream is sent to the cloud, in which multiple docker containers process the data in parralel. The authors were able to improve input frame rate by 158\%, using two containers, to achieve real-time image processing. 



%P8: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7041896
%P9: http://web.engr.illinois.edu/~zestrad2/papers/scpe.pdf

% P5 - Based on our results, we would suggest not combining disk- and memory-intensive workloads into different containers due to the inherent performance degradation observed while putting them together onto the same physical machine. On the other hand, we observed that by consolidating I/O- and CPU-intensive workloads, it is possible to alleviate the performance impacts
