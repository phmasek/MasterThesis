\iffalse \bibliography{include/backmatter/magnus,include/backmatter/philip} \fi

\chapter{Related Work} \label{section:relatedwork} 
In this section we introduce (i) the process of identifying related work and (ii) discuss current research on scope of this study. % for the purpose of 
%This section aims to explore literature on using lightweight containers for deployment. 
% aims to show how this research fits into a larger research context 




%---------------------------------------------------%
%---------------------------------------------------%
\section{Gathering Related Work}
The snowballing search approach for systematic literature studies is used to find relevant literature on the topic of this paper. The snowballing approach is complementary to a traditional database search. Specifically, the reference list and citations of a paper are studied in order to identify additional papers. The snowballing search approach is used to ensure good coverage of current literature.\\

The guidelines for conducting a snowballing search approach, presented by Wohlin \cite{Wohlin} are followed. The steps to conduct a snowballing procedure involve selecting a start set of papers and apply forward and backward snowballing on each paper respectively. The process iterates until no new papers are found. To identify a start set of papers, keywords are extracted from the research questions, taking synonyms into account. Formulating a search-string from keywords that are broad and cover multiple areas of research may result in collecting large amounts of literature that span different subject domains. For that reason, broad keywords should be broken down into more specific and detailed keywords specific to the study. The search string is then applied to a database that preferably searches multiple publishers in order to avoid publisher bias. The papers are then screened according to inclusion/exclusion criteria. An exclusion criteria could state that all online material be excluded. \\

Backward and forward snowballing is then conducted on the start set. Backward snowballing is the process of studying the reference list to identify new papers. Looking at the place of reference and reading the title and abstract of the paper is a good starting point for inclusion, however, final inclusion states that the entire paper must be read. Subsequently, forward snowballing is the process of identifying papers that cite the paper under inspection. The same process of reading the title, abstract and place of reference is applied in order to include new literature that is found during the procedure. 

%-- Why Snowballing ?
%snowballing to ensure good coverage of literature
%snowballing over just a typical database search
%since we're writing about new tech, new papers must certainly reference at least one paper among previously releant studies

%-- Outline the steps in snowballing
%let’s outline them here, so the steps are clear. (what are iterations)
%Then, you describe the steps and their outcomes. 
%A figure showing the process could be used if you judge it fits

%-------------------------------
\subsection{Snowballing Search Results}
This section introduces the results from performing the snowballing search procedure described in the previous section. First the start-set is formulated and introduced, where two sets of iterations are performed. 

\subsubsection*{Start Set}
A database search on Scopus \cite{scopus} is performed to identify the start set: the search string is found in \ref{search-string}.  The actual search was conducted May 10, 2016. The Scopus database returns literature from multiple publishers. The search resulted in finding 215 papers. The screening process was then applied to the 215 papers. Papers were added to the start set upon meeting the inclusion/exclusion criteria. Papers were included if found to be about input/output benchmarking, CPU benchmarking or software deployment, within the subject area of virtual containers (preferably Docker) and/or within the context of cyber physical systems. Papers were excluded if not being peer-reviewed. In total, 9 candidates for inclusion were identified. The 9 papers are identified in table~\ref{lr-startset}, denoted P1, P2 and so on.

\begin{table}[]
\centering
\begin{tabular}{p{15cm}}
TITLE-ABS-KEY(Performance OR Comparison OR Latency OR Evaluation OR Container-Based OR Linux Containers OR Lightweight Virtualization OR Container Cloud OR Docker) AND ( LIMIT-TO(SUBJAREA,"COMP" ) )
\end{tabular}
\caption{Search String}
\label{search-string}
\end{table}

%-----------------------%
\begin{table}[]
\begin{tabular}{lp{13cm}}
{[}P1{]}  & C. N. Mao, M. H. Huang, S. Padhy, S. T. Wang, W. C. Chung, Y. C. Chung, and C. H. Hsu, “Minimizing latency of real-time container cloud for software radio access networks,” in 2015 IEEE 7th International Conference on Cloud Computing Technology and Science (CloudCom), Nov 2015, pp. 611–616.                                  \\
{[}P2{]}  & A. Krylovskiy, “Internet of things gateways meet linux containers: Performance evaluation and discussion,” in Internet of Things (WF-IoT), 2015 IEEE 2nd World Forum on, Dec 2015, pp. 222–227.                                                                                                                                      \\
{[}P3{]}  & M. Raho, A. Spyridakis, M. Paolino, and D. Raho, “Kvm, xen and docker: A performance analysis for arm based nfv and cloud computing,” in Information,Electronic and Electrical Engineering (AIEEE), 2015 IEEE 3rd Workshop onAdvances in, Nov 2015, pp. 1–8.                                                                         \\
{[}P4{]}  & R. Morabito, J. Kj\"allman, and M. Komu, “Hypervisors vs. lightweight virtualization: A performance comparison,” in Proceedings of the 2015 IEEE Interational Conference on Cloud Engineering, ser. IC2E ’15. Washington, DC, USA: IEEE Computer Society, 2015, pp. 386–393.                                                      \\
{[}P5{]}  & M. G. Xavier, I. C. D. Oliveira, F. D. Rossi, R. D. D. Passos, K. J. Matteussi, and C. A. F. D. Rose, “A performance isolation analysis of disk-intensive workoads on container-based clouds,” in 2015 23rd Euromicro International Conference on Parallel, Distributed, and Network-Based Processing, March 2015, pp. 253–260. \\
{[}P6{]}  & W. Felter, A. Ferreira, R. Rajamony, and J. Rubio, “An updated performance comparison of virtual machines and linux containers,” in Performance Analysis of Systems and Software (ISPASS), 2015 IEEE International Symposium on, March 2015, pp. 171–172.                                                                            \\
{[}P7{]}  & C. Ruiz, E. Jeanvoine, and L. Nussbaum, “Performance evaluation of containers for hpc,” in Euro-Par 2015: Parallel Processing Workshops: Euro-Par 2015 International Workshops, Vienna, Austria, August 24-25, 2015, Revised Selected Papers. Cham: Springer International Publishing, 2015, pp. 813–824. \\
{[}P8{]}  & R. Wu, Y. Chen, E. Blasch, B. Liu, G. Chen, and D. Shen, “A container-based elastic cloud architecture for real-time full-motion video (fmv) target tracking,” in 2014 IEEE Applied Imagery Pattern Recognition Workshop (AIPR), Oct 2014, pp. 1–8.                                                                                  \\
{[}P9{]} & Z. Estrada, F. Deng, Z. Stephens, C. Pham, Z. Kalbarczyk, and R. Iyer, “Performance comparison and tuning of virtual machines for sequence alignment software,” Scalable Computing, vol. 16, no. 1, pp. 71–84, 2015.
\end{tabular}
\centering
\caption{Start Set}
\label{lr-startset}
\end{table}
%-----------------------%
%------Iteration 1------ 
\subsubsection*{Iteration 1: Backward Snowballing}
\textbf{P1} includes 26 references where one reference is already included in the start set (paper P6). Based on the inclusion criteria, one paper was included. The paper identified and thus included in the start set is: \\

%-------------------------------
\begin{labeling}{[{[}C10{]}]}
\item [{[}\textbf{C1}{]}]  M. G. Xavier, M. V. Neves, F. D. Rossi, T. C. Ferreto, T. Lange and C. A. F. De Rose, “Performance Evaluation of Container-Based Virtualization for High Performance Computing Environments,“ 2013 21st Euromicro International Conference on Parallel, Distributed, and Network-Based Processing, Belfast, 2013, pp. 233-240.
\item
\end{labeling}
%-------------------------------

Table~\ref{back-snow} shows the result of backward snowballing on the remaining eight papers. The results are presented in a table to avoid redundant text as the process and results of backward snowballing for each paper are very similar. In all papers, except P1, no new papers matched the inclusion criteria after reading the title and abstract. Furthermore, most of the papers in the start set reference to each other, as seen in column three of table~\ref{back-snow}. All papers in the start set contain reference to C1, except papers P2 and P8. Similarly, all papers in the start set reference to P6 except papers P5, P6 and P8. This shows that there is a strong connection between all papers in the start set. 

%-------------------------------
\begin{table}[]
\begin{tabular}{|>{\centering\bfseries}m{1in} |>{\centering}m{1in}| >{\centering}m{1in} |>{\centering\arraybackslash}m{1in}|}
\hline
\textbf{Start Set Paper} & \textbf{No. References} & \textbf{Reference to Start Set} & \textbf{New Papers Identified} \\ \hline
\textbf{P1}              & 26                      & P6                                          & C1                  \\ \hline
\textbf{P2}              & 21                      & P6, P4                                      & 0                   \\ \hline
\textbf{P3}              & 47                      & P6, C1                                      & 0                   \\ \hline
\textbf{P4}              & 42                      & P6, P2, C1                                  & 0                   \\ \hline
\textbf{P5}              & 46                      & C1                                          & 0                   \\ \hline
\textbf{P6}              & 50                      & C1                                          & 0                   \\ \hline
\textbf{P7}              & 19                      & P6, C1                                      & 0                   \\ \hline
\textbf{P8}              & 18                      & 0                                           & 0                   \\ \hline
\textbf{P9}              & 31                      & P6, C1                                      & 0                   \\ \hline
\end{tabular}
\centering
\caption{Results from Backward Snowballing in Iteration 1}
\label{back-snow}
\end{table}
%-------------------------------

\subsubsection*{Iteration 1: Forward Snowballing}
The next step is to examine the citation to all papers that are in the start set. All papers were searched for citations using Google Scholar. The Scopus database was chosen not to be used for the forward snowballing procedure since it was shown that Google Scholar was more accurate in finding cited papers. The exclusion criteria for this snowballing search procedure excludes all non peer reviewed papers. However, during the forward snowballing search, a very relevant paper was found in regards to this study. It was then decided to include the paper as part of the related work. The specific paper included is: \\


\begin{labeling}{[{[}C10{]}]}
\item [{[}\textbf{C2}{]}]  Welch, James Matthew. Performance Optimization of Linux Networking for Latency-Sensitive Virtual Systems. Diss. ARIZONA STATE UNIVERSITY, 2015.

\item
\end{labeling}

\begin{table}[]
\begin{tabular}{|>{\centering\bfseries}m{1in} |>{\centering}m{1in}|>{\centering\arraybackslash}m{1in}|}
\hline
\textbf{Start Set Paper} & \textbf{No. Citations}  & \textbf{New Papers Identified} \\ \hline
\textbf{P1}              & 0                       & 0                             \\ \hline
\textbf{P2}              & 0                       & 0                             \\ \hline
\textbf{P3}              & 0                       & 0                             \\ \hline
\textbf{P4}              & 8                       & C2				               \\ \hline
\textbf{P5}              & 2                       & 0                             \\ \hline
\textbf{P6}              & 81                      & 0                             \\ \hline
\textbf{P7}              & 4                       & 0                             \\ \hline
\textbf{P8}              & 1                       & 0                             \\ \hline
\textbf{P9}              & 1                     & 0                             	\\ \hline
\end{tabular}
\centering
\caption{Results from Forward Snowballing in Iteration 1}
\label{forward-snow}
\end{table}

\subsubsection*{Iteration 2: Backward Snowballing}
Two additional papers to the start set were found in iteration one of the snowballing procedure. Thus, backward and forward snowballing is applied to C1 and C2.\\ 

\textbf{C1} has 32 references. Of the 32 references, 16 references are excluded based on being references to online material. A large number of the resulting references have already been analysed in the previous iteration. No new papers were identified for inclusion.\\ 

\textbf{C2} has 69 references with reference to C1, P4, P6. No additional papers were found when studying the reference list of the paper.

\subsubsection*{Iteration 2: Forward Snowballing}
\textbf{C1} has been cited by 104 papers. When reviewing the list of cited papers, many of them have already been reviewed during the snowballing procedure.  Analysing the list of papers resulted in no additional candidates for inclusion.\\ 
 
\textbf{C2} has no citations. This is expected since C2 is not a published paper. 


\subsection{Outcome}
The snowballing search procedure resulted in finding nine papers during the database search. Two additional papers were identified during forward and backward snowballing. The snowballing procedure enabled good coverage of literature for related work and helped identify the current status of research in the field of container virtualization. 
%a qualitative outcome of the snowballing procedure. What did it actually give us, and do for the paper? 
%However, since there was only one new paper included in the start-set during the backward snowballing, this sheds light on the fact that this study is within a narrow scope, and further motivates the need for carrying out this study. 

%What did we get out of doing the snowballing

%--------------------------------------------%
%--------------------------------------------%
\section{Related Work} 

The paper by C. Berger \cite{cberger} presents the exploration of a continuous integration and continuous deployment in the context of self-driving vehicles that utilises lightweight Docker containers. The deployment strategy make use of a number of Docker containers that build and ship signed packages in a container ready for use. The paper however does not look to identify the precise performance overhead when using Docker as part of the deployment strategy but addresses the need for it in future work. Utilising Docker for CPS's lacks in current literature. However, the authors of \cite{2iot} identify the challenge of deploying, maintaining and configuring software for IoT gateways and investigate using virtual containers to solve these challenges. They identify the performance overhead of using Docker as a deployment platform on two different versions of the Raspberry Pi System on Chip (SoC) \cite{raspberry}. They identify that there are clear benefits offered by containerized deployment on resource constrained devices but further research is needed in the domain of IoT. This shows a need for continuous deployment in embedded, resource contained and high performing applications. The authors of \cite{2iot} do recommend a case-by-case analysis when considering using Docker as a deployment platform for IoT devices. This can be understood as in \cite{gonz}, who also experiment with Docker on Raspberry Pi do not report any substantial cost to performance when utilising Docker. In \cite{gonz}, the study explores Docker as a deployment platform for a generic modular architecture for industrial automated cyber physical systems. An example is used building an automated guided vehicular CPS with this modular architecture. The authos state that having a modular architecture - given by Docker - decouples the complexity of CPS's into simpler subsystems, that different teams can individually develop on. The authors of \cite{gonz} conclude that using a real-time enabled Linux kernel as future work. \\

Current literature \cite{p6} presents compelling evidence for the existence of performance overhead when running applications within a virtual environment. This evidence is based on an exploration of Docker, KVM, and native environments without exploring the impact such environments have on time critical software. In a study presented my Mao et. al, the authors investigate the next generation of Radio Access Networks (RANs), used by telecom providers and that such systems are moving towards the cloud \cite{p1}. Traditional RANS are hardware dependent equipment which are expensive and lack scalability. Moving traditional RANs to the cloud as software RANs is a challenging task due to the latency requirements of cellular networks. There is a similarity in the challenges of software with high hardware dependability and time-sensitivity in \cite{p1} and to the challenges within the domain of autonomous vehicles. To overcome the time-sensitive requirements of software RANs, the authors use a real-time enabled Linux kernel, specifically the RT\_PREEMPT patch, and measure computational and networking latency when using Docker for real-time applications. The cyclic test \cite{cycl} is used to measure computational latency and is a common tool to measure real-time capabilities of an operating system. The worst case execution time is measured and reported in the study. The results of the study show that running real-time applications inside a Docker container achieves near-native performance, while the performance of virtual machines incur much higher latencies \cite{p1}. However, running multiple Docker containers on different hosts incur higher overhead. \\

In a similar study presented by Welch \cite{c2}, the author identifies the performance overhead of using Docker for latency sensitive applications in the context of cloud computing. In \cite{c2}, the RT\_PREEMPT kernel patch for Linux Kernel 3.18.20 is used to identify the networking performance of Docker containers in comparison to virtual machines. The results show that the Docker containers have generally higher bandwidth and lower latency that virtual machines. However, in both \cite{Andreas} and \cite{p6} the network address translation protocol introduces considerable overhead. In papers \cite{p6,p3,p4,p7,c1} they state that overhead by using Docker is negligible and CPU, memory, disk and network performance is near native. However, \cite{p5} presents results on the performance overhead of Docker and recommend not combining disk and memory intensive workloads into different containers due in an apparent degradation of performance they observers. They suggest consolidating I/O and CPU intensive workloads to alleviate this problem. 

%P8: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7041896
%P9: http://web.engr.illinois.edu/~zestrad2/papers/scpe.pdf

% P5 - Based on our results, we would suggest not combining disk- and memory-intensive workloads into different containers due to the inherent performance degradation observed while putting them together onto the same physical machine. On the other hand, we observed that by consolidating I/O- and CPU-intensive workloads, it is possible to alleviate the performance impacts
